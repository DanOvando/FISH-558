---
title: "FISH 558 Homework 4 - Mosquito MCMC"
author: "Dan Ovando"
date: "October 31, 2015"
output: 
  pdf_document:
    fig_caption: yes
---

```{r global_options, include=FALSE}
rm(list = ls())

run <- '3.3'

run_folder <- paste('Results/',run,'/',sep = '')

if (dir.exists(run_folder) == F){dir.create(run_folder, recursive = T)}

set.seed(54321)
library(knitr)
knitr::opts_chunk$set(fig.path='Figs/', echo=FALSE, warning=FALSE, message=FALSE)
library(gridExtra)
library(ggplot2)
library(plyr)
library(dplyr)
library(tidyr)
library(broom)
library(coda)
library(ggmcmc)
# library(LaplacesDemon)
library(foreach)
library(scales)
library(stargazer)
library(mvtnorm)
library(doMC)
library(proftools)
source('mozzy_likelihood.R')
source('mozzy_mcmc.R')
source('multi_mozzy_mcmc.R')
source('thin_mcmc.R')


```
## Model

Our goal for this assignment is to fit a Bayesian hierarchical model to data of counts of mosquitoes at various distances along 20 different streams. The hierarchical nature of the model works as follow. At the top level, we put priors on $\mu_{F}$ (the expected count at the river-mouth of stream 1) and $\mu_{L}$ (the expected count at the river-mouth of stream 20), and $\overline(\alpha)$ (the population mean of the rate of change in mosquito counts with density), as well as their associated variances. At the next level, these parameters are used to estimate stream-specific values of $\mu_{i}$ and $\alpha_{i}$. Moving down, we then estimate counts at distance *j*, and finally estimate the likelihood of the data using the estimated counts and the observed counts. 

## Data

The data are shown in Fig.1. We see a broad trend of roughly exponential growth in mosquito counts as a function of distance upstream. 

```{r load data, fig.cap='Mosquito count data'}

dat <- read.csv(file = 'hwk4_data.csv',stringsAsFactors = F) %>%
  dplyr::rename(stream = Steam) %>%
  gather('distance','count', grep('X',colnames(.))) %>%
  mutate(distance = as.numeric(gsub('X','',distance)))

colnames(dat) <- tolower(colnames(dat))

par_guess <- (read.csv(file = 'hwk4_pars.csv', stringsAsFactors = F))

colnames(par_guess) <- tolower(colnames(par_guess))


vcov <- read.csv(file = 'hwk4_vcov.csv', stringsAsFactors = F)

rownames(vcov) <- colnames(vcov)


dat_plot <- dat %>%
  ggplot(aes(distance, count, fill = stream, size = count)) + 
  geom_point(shape = 21) + 
  facet_wrap(~stream) + 
  xlab('Distance') + 
  ylab('Count') + 
  theme_light() + 
  theme(legend.position = 'none')

# vcov.plot <- vcov %>%
#   mutate(var1 = colnames(.)) %>%
#   gather('var2','covar',which(grepl('var1',colnames(.)) == F)) %>%
#   ggplot(aes(var1,var2,fill = covar)) +
#   geom_tile()
#   
  dat_plot

```

## The Likelihoods

The posterior of any cycle in our MCMC chain is divided into the likelihood of the data and prior probabilities. 

The data are Poisson distributed, so the likelihood is given as the log of the likelihood of the observed counts at stream *i* at distance *j* if they came from a Poisson distribution with mean $\mu_{i,j}$

Working our way from bottom to top in the priors, the likelihood of a given value of $\mu_{i}$ is calculated from a normal distribution with mean $\mu_{f} + \frac{(\mu_{l} - \mu_{f}) - (i - 1)}{(20 - 1)}$ and standard deviation $\sigma_{\mu}$.

The prior probability of a given value of $\alpha_{i}$ is also calculated from a normal distribution, with mean $\overline{\alpha}$ and standard deviation $\sigma_{\alpha}$. 

The hyper-prior probability of given values of $\mu_{f}$, $\mu_{L}$, and $\overline{\alpha}$ are assumed uniform. Since we know that $\mu$ cannot be negative (as much as we'd all love negative mosquitoes), we define the interval of the $\mu_{f/L}$ hyper-priors as U ~[0,Inf]. $\overline{\alpha}$ is drawn from  U ~[-Inf,Inf]. 

The hyper-prior probability of given values of $\sigma_{\mu}$ and $\sigma_{\alpha}$ are assumed normal with mean 1 and .01 respectively, and standard deviations of 0.1

The posterior probability of a given cycle *c* of an MCMC chain is then given as

$$Posterior_{c}  =  \sum_{i} \sum_{j} dpois(count_{i,j},\mu_{c,i,j}, log = T) + \sum_{i} dnorm(\mu_{c,i},f(uf,ul,i), \sigma_{\mu}, log = T) +...$$

$$\sum_{i} dnorm(\alpha_{c,i},\overline{\alpha},\sigma_{\alpha}, log = T) 
+ dnorm(\sigma_{\mu},1,.1, log = T) + dnorm(\sigma_{\alpha},.01,.1, log = T)...$$

$$+ dunif(\mu_{f},0,Inf, log = T) + dunif(\mu_{L},0,Inf, log = T)$$

## Results

```{r mcmc process}

load(paste(run_folder,'mozzy_mcmc.Rdata', sep = ''))

post <- thin_mcmc(chains = mcmc_results$posteriors, thin_every = dim(mcmc_results$posteriors)[1]/1000)


best_beach <- post %>%
  dplyr::select(.,contains('mu')) %>%
  dplyr::select(mu.1:mu.20) %>%
  gather('parameter','value') %>%
  mutate(stream = gsub('.*\\.','',parameter)) %>%
  mutate(stream = as.numeric(stream)) %>%
  group_by(stream) %>%
  mutate(mean_count = mean(value)) %>%
  arrange(mean_count) %>%
  ggplot(aes(factor(stream),value, fill = mean_count)) + 
  scale_fill_continuous(low = 'green', high = 'red',guide = F)+ 
  geom_boxplot() + 
  xlab('Stream') + 
  ylab('Expected Mosquito Counts at Rivermouth') + 
  theme_light()
  #   stream_pars <- gather(as.data.frame(pars),'param','value') %>%
#     mutate(stream = suppressWarnings(as.numeric(gsub('.*\\.', '',param))),
#            param.name = (gsub('\\..*','',param))) %>%
#     subset(is.na(stream) == F) %>%
#     dplyr::select(-param) %>%
#     spread(param.name,value)
# #     mutate(mu = pmax(0,mu))

# Posterior histograms ----
post_hist <- post %>%
  select(-ll,-deviance) %>%
  gather('parameter','value') %>%
  ggplot(aes(value)) +
  geom_histogram(aes(fill = parameter)) + 
  scale_fill_discrete(guide = F) + 
  facet_wrap(~parameter, scales = 'free') + 
  theme_light() + 
  theme(text = element_text(size = 8), axis.text.x = element_text(size = 5)) + 
  xlab('Value') + 
  ylab('Count')



# Autocorrelation Plots ----

autocorr_plot <- ggs_autocorrelation(ggs(mcmc(select(post,-ll,-deviance))),nLags = 25) + 
  theme_light() + 
    theme(text = element_text(size = 8), axis.text.x = element_text(size = 5))

lag_1 <- rep(NA,dim(post)[2])
for (j in 1:dim(post)[2])
{
  lag_1[j] <- acf(post[,j], plot = F)$acf[2]
}

# hist(lag_1)

acf_hist <- ggplot(data.frame(acf = lag_1), aes(acf)) + 
  geom_histogram(binwidth = .05) + 
  xlab('Lag 1 ACF') + 
  ylab('Count') + 
  theme_light()

# achist <- post %>%
#   select(-ll,-deviance) %>%
#   gather('parameter','value') %>%
#   group_by(parameter) %>%
#   mutate(arg = as.numeric(acf(value, plot = F)$acf)[2])

  

# Correlation Plots ----

corrplot <- ggs_crosscorrelation(ggs(mcmc(select(post,-ll,-deviance)))) +
  theme(text = element_text(size = 8)) + scale_fill_gradient2(name = 'Correlation', low = 'red',high = 'blue', mid = 'white', midpoint = 0, na.value = 'blue', limits = c(-1,1))

# Partial Chain ---

partial_chain <- ggs_compare_partial(ggs(mcmc(select(post,-ll))), partial = 0.1) + 
    theme_light() + 
    theme(text = element_text(size = 8), axis.text.x = element_text(size = 5)) + 
  facet_wrap(~Parameter, scales = 'free') + 
  xlab('Value') + 
  ylab('Count')


# Gweke etc. ----

gweke <- ggs_geweke(ggs(mcmc(select(post,-ll,-deviance)))) +
   theme_light() + 
    theme(text = element_text(size = 8), axis.text.x = element_text(size = 5),
          legend.position = 'none')

b <- mcmc(select(post,-ll))

heidel <- ((heidel.diag(mcmc(select(post,-ll)))))

# kable((heidel), caption = 'Heidelberg - Welch convergance diagnostics')

```


We ran 1.5 million cycles, with a burn-in of `r (.6*1.5)` million cycles, thinning every 300th cycle, leaving us with 1000 samples from the posterior distribution. Histograms of the 45 posteriors estimated by our model are shown in Fig.2. The covariance matrix was tuned via an adaptive scalar during the burn-in to achieve a desired acceptance rate near 20%. The final acceptance rate of the chain was `r round(100*mcmc_results$accepted_runs$perc_selected,2)`%. 


```{r, fig.cap= 'Histograms of posterior distributions of estimated model parameters'}

post_hist

```

Examining the cross-correlations of the 45 estimated parameters(Fig.3), we see that $\alpha_{i}$ and $\mu_{i}$ are highly negatively correlated, meaning that the streams with the highest expected counts at the river-mouth tend to exhibit the lowest rate of change in expected counts as one moves upstream (Fig.3). There is the potential for some confounding effects between these two parameters . 

We seem some evidence that that $\alpha_{i}$ and $\mu_{i}$ are positively correlated with themselves in space (meaning that streams with high that $\alpha_{i}$ or $\mu_{i}$'s show some tendency to be near streams with high $\alpha_{i}$'s and $\mu_{i}$'s). 

$\mu_{L}$ and $\mu_{F}$ are highly negatively correlated with each other as well, and both show some evidence of being negatively correlated with $\alpha$. 
 
```{r, fig.cap="Cross correlations of estimated parameters"}
corrplot
```

The number of cycles, burn-in, and thinning ratio for our MCMC were selected based on the Geweke statistic, visual assessment of auto-correlation,  partial-chain comparisons, and the effective sample size. 

The Geweke statistic indicates whether the mean of the  early part (first 10%) of the MCMC chain is significantly different than the later part (last 50%) of the MCMC chain for each of our parameters. We see that none of our estimated parameters fail the Geweke test (Fig.4). 

```{r gweke plot, fig.cap = 'Geweke statistics for the estimated parameters'}

gweke

```

We see that the selected MCMC parameters result in sufficiently low auto-correlation values for all of our parameters (Fig.5), with all less than 0.1/-0.1 lag 1 auto correlation (though we could perhaps reduce it some). 

```{r, fig.cap= 'Histogram of lag 1 auto-correlation of estimated parameter traceplots'}
acf_hist
```

For the partial chain analysis, we compare the posterior densities of our parameters from the full chain to the posterior densities using only the last 10% of the chain. Post thinning and burn-in, our MCMC chain, and the associated posterior distributions, should not be still "evolving" over cycles. If it were, we might expect to see that the posteriors from the partial chain differ substantially from the broader chain. Our results show that the posterior densities from the complete and partial chains are nearly identical, providing evidence that our chain is stable (Fig.6). 

```{r, fig.cap= 'Comparison of posterior densities between partial (last 10%) and complete MCMC chains'}

partial_chain

```

The effective sample size of each of our parameters if also sufficient for each of our parameters (Fig.7)

```{r, fig.cap= 'Effective sample size of model parameters'}

eff_sample <- data.frame(effective.ss = effectiveSize(mcmc(post))) %>%
  mutate(parameter = rownames(.)) %>%
  subset(!parameter %in% c('ll','deviance')) %>%
  ggplot(aes(factor(parameter),effective.ss)) + 
  geom_bar(position = 'dodge', stat = 'identity') + 
  coord_flip() + 
  xlab('Parameter') + 
  ylab('Effective Sample Size') + 
  theme_light()

eff_sample

```

All of our parameters passed the Heidelberg-Welsh test, providing further evidence that our number of cycles, burn-in, and thinning ratio are appropriate (I can't figure out how to extract things from class "heidel.diag" for the life of me). 

To verify convergence of the chain, we also ran four additional chains, each with randomly selected seeds and jittered starting values. We use these chains to compare the posterior densities of our parameters across all four chains to ensure that we obtain similar distributions, and to perform a Gelman-Rubin test to check for convergence across chains. 

Comparing the posterior distributions for the 45 parameters across all 4 chains, we see that they are almost exactly identical. This suggests that our model is in fact stable and converged, since 4 separate chains with unique starting values and random seeds converged on the same final distribution (Fig.8).

```{r, fig.cap = 'Comparison of posterior densities among chains'}

load(paste(run_folder,'multi_chain_mcmc.Rdata', sep = ''))

mc_posts <- list() 

# mcmc_posts <- list()

mc_sims <- dim(multichain_mcmc_results$posteriors[[1]])[1]

for (i in 1:length(multichain_mcmc_results$posteriors)){
  
  mc_posts[[i]] <- thin_mcmc(chains = multichain_mcmc_results$posteriors[[i]], thin_every = mc_sims / 1000)
  
  # mcmc_posts[[i]] <- mcmc(select(thin_mcmc(chains = multichain_mcmc_results$posteriors[[i]], thin_every = mc_sims / 2000),-ll,-deviance))

}

# b <- mcmc.list(mcmc_posts)

# gelman.diag(b,autoburnin = F)

mc_posts <- ldply(mc_posts)

base_post <- data.frame(run = 0, post)

chain_posts <- rbind(base_post,mc_posts)

chain_post_hist <- chain_posts %>%
  select(-ll,-deviance) %>%
  gather('parameter','value',mu.f:alpha.20) %>%
  ggplot(aes(value, fill = factor(run))) +
  geom_density(alpha = 0.2, color = 'black') + 
  scale_fill_brewer(name = 'Chain',palette = 'Spectral') + 
  facet_wrap(~parameter, scales = 'free') + 
  theme_light() + 
  theme(text = element_text(size = 8), axis.text.x = element_text(size = 5)) + 
  xlab('Value') + 
  ylab('Count')

  chain_post_hist

```
```{r gelman rubin}

  gelman_rubin <- (chain_posts) %>%
    rename(Chain = run) %>%
    group_by(Chain) %>%
    summarize(Var_Deviance = var(deviance), Mean_Deviance = mean(deviance),n = length(deviance)) %>%
    ungroup() %>%
    mutate(W = mean(Var_Deviance),
           B = var(Mean_Deviance),
#            m = length(unique(Chain)),
#            Vhat = (1 - 1/n)*W + (1/n)*B,
#            R = sqrt(Vhat / W))
           R = (B + W)/W)
  
#   kable(gelman_rubin, digits = 2,caption = 'Gelman-Rubin diagnostics across 4 chains')

```


For the Gelman-Rubin test, we calculate the deviance for each cycle of the chain as $-2*LL$, where *LL* is the log-likelihood of the observed vs. predicted ($\mu_{i,j}$) counts. We then calculate *W* as the mean of the variance of the deviance in each chain, and *B* as the variance of the mean of the deviance in each chain, and calculate the *R* statistic through the approximation $\frac{B + W}{W}$. Our resulting value is *R* =  `r round(unique(gelman_rubin$R),2)`, suggesting that our chains have in fact converged. 

### Decision Guidance

We have presented a slew of graphs to date, which help with the diagnostics of the model but are not necessarily informative to a decision maker. Suppose then that I am a surfer trying to use this model to decide where to camp for a surf trip. I know that river-mouths often create good points or sandbanks for waves, so I'm interested at camping near a river-mouth. However, I hate mosquitoes. So, I'm interested in which rivers the model suggests have the highest counts of mosquitoes at the river-mouth, $\mu_{i}$. Comparing the posterior distributions of $\mu_{i}$ predicted by the model, we see that my best option is to camp among the first three river-mouths if my goal is minimizing mosquitoes (Fig.9). 

```{r, fig.cap = 'Posteriors of expected mosquito counts at rivermouths'}

best_beach

```

## Part 2

Our hypothetical surfer has now decided to go on a hike up stream #12 (latitude 12) since it has gone flat and he is bored, and wants to stop for lunch 15km up from the river-mouth. However, he is once again worried about mosquitoes, and so wants to know the predicted counts of mosquitoes at this site. The instructions call for a posterior distribution to be estimated. To obtain model estimates of predicted counts 15km's up stream 12, we first draw all values from *C*  retained cycles for $\mu_{c,i = 12}$ and $\alpha_{c,i = 12}$ from the posterior of our model. We then use these to estimate the expected count 15km up stream 12 per $\mu_{c,i = 12,j = 15} = \mu_{c,i = 12}e^{\alpha_{c,i = 12}*15}$. The resulting distribution of *C* estimates of  $\mu_{c,i}$ are plotted in Fig.10 . 

Our results show that the posterior distribution of counts 15km down stream 12 do not differ significantly from the observed counts at 10 and 20km, so as long as we're OK with those predicted counts of ~25 mosquitoes 15km along stream 12 looks like a good place for lunch, especially as the counts start to climb much further up the stream.

```{r part two fig, fig.cap= 'Posterior distributions of counts at 15km down stream 12. A) Posterior distribution (violin) inserted to observed counts for stream 12 B) histogram of posterior distribution of counts 15km down stream 12'}

stream_num <- 12

inter_distance <- 15

post <- thin_mcmc(chains = mcmc_results$posteriors, thin_every = dim(mcmc_results$posteriors)[1]/1000)


stream_post <- data_frame(mu = post[,paste('mu.',stream_num, sep = '')], alpha = post[,paste('alpha.',stream_num, sep = '')] ) %>%
  mutate(expected_count = mu * exp(alpha * inter_distance),
        rand_count = rpois(length(expected_count),lambda = expected_count))

part_b_plot <- dat %>%
  subset(stream == stream_num) %>%
  ggplot(aes(distance,count, fill = distance)) + 
  geom_point(shape = 21, size = 3) +
  geom_violin(data = stream_post,aes(inter_distance, expected_count, fill = inter_distance),color = 'black') + 
  scale_fill_continuous(guide = F,name = 'Distance (km)',low = 'yellow',high = 'red') + 
  xlab('Distance (km)') + 
  ylab('count') + 
  theme_light() + 
  ggtitle('A')


part_b_plot_hist <- dat %>%
  subset(stream == stream_num) %>%
  ggplot() +
  geom_histogram(data = stream_post,aes(expected_count),color = 'black') + 
  xlim(c(20,32)) + 
  xlab('Predicted Count') + 
  ylab('Count') + 
  theme_light() + 
  ggtitle('B')

grid.arrange(part_b_plot,part_b_plot_hist,nrow = 2,ncol = 1)


```

## Part 3

Lastly, our surfer might wonder whether this model really is a good predictor of mosquito counts. To address this concern, we compare the posterior predictive distribution of counts along stream 7 to the observed counts. We first draw *C* estimates of $\mu_{c,i = 7,j}$ for each distance *j* with observations. We then estimate a posterior predictive distribution per our assumption that the counts are Poisson distributed, and so generate *C* predicted counts using *rpois(1,$\mu_{c,i = 7,j}$)*. 

We see that all of the observed counts fall within the 95% credibility interval of the posterior predictive distributions (Fig.11). However, we see some indication that our model does not fit the data as well at low counts (near the river-mouth), especially when the observed counts near 0. On the whole our model appears to capture the broad trend in mosquito counts well, but is not particularly precise, especially at low counts. The model certainly appears adequate at capturing the relative magnitude and trends in mosquito counts, but its performance suffers closer to the river-mouth of stream 7, where the observed counts are closer to zero. 

```{r part three plot, fig.cap= 'Posterior predictive distribution of counts along the stream of at latitude 7. Points are observed counts, boxplots represent the posterior predicted distribution from the MCMC at that distance'}

stream_num <- 7

post <- thin_mcmc(chains = mcmc_results$posteriors, thin_every = dim(mcmc_results$posteriors)[1]/1000)

stream_dat <- subset(dat, stream == stream_num)


stream_post <- data_frame(stream = stream_num,mu = post[,paste('mu.',stream_num, sep = '')], alpha = post[,paste('alpha.',stream_num, sep = '')]) %>%
  full_join(stream_dat, by = 'stream') %>%
  mutate(expected_count = mu * exp(alpha * distance),
        rand_count = rpois(length(expected_count),lambda = expected_count))

part_c_plot <- dat %>%
  subset(stream == stream_num) %>%
  ggplot(aes(factor(distance),count, fill = distance)) + 
  geom_point(shape = 21, size = 3) +
  geom_boxplot(data = stream_post,aes(factor(distance), rand_count, fill = distance),color = 'black', alpha = 0.3)  + 
  scale_fill_continuous(guide = F,name = 'Distance (km)',low = 'yellow',high = 'red') + 
  xlab('Distance (km)') + 
  ylab('count') + 
  theme_light()

part_c_plot

```
